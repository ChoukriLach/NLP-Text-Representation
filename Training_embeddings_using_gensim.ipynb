{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0177e972",
   "metadata": {},
   "source": [
    "## Training Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c81afba",
   "metadata": {},
   "source": [
    "Word embeddings are an approach to representing text in NLP. In this notebook we will demonstrate how to train embeddings using Genism. Gensim is an open source Python library for natural language processing, with a focus on topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e75442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7228c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training data\n",
    "#Genism word2vec requires that a format of ‘list of lists’ be provided for training where every document contained in a list.\n",
    "#Every list contains lists of tokens of that document.\n",
    "corpus = [['dog','bites','man'], [\"man\", \"bites\" ,\"dog\"],[\"dog\",\"eats\",\"meat\"],[\"man\", \"eats\",\"food\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e926c",
   "metadata": {},
   "source": [
    "Hyperparameters : \n",
    "    \n",
    "- **sg - Selecting the training algorithm: 1 for skip-gram else its 0 for CBOW. Default is CBOW.**\n",
    "- **min_count- Ignores all words with total frequency lower than this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf028a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "model_cbow = Word2Vec(corpus, min_count=1,sg=0) #using CBOW Architecture for trainnig\n",
    "model_skipgram = Word2Vec(corpus, min_count=1,sg=1)#using skipGram Architecture for training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f3f28c",
   "metadata": {},
   "source": [
    "### Continuous Bag of Words (CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb933409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=6, vector_size=100, alpha=0.025>\n",
      "['man', 'dog', 'eats', 'bites', 'food', 'meat']\n"
     ]
    }
   ],
   "source": [
    "#Summarize the loaded model\n",
    "print(model_cbow)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(model_cbow.wv.key_to_index)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165a22c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
      "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
      " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
      " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
      "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
      "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
      "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
      " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
      " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
      "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
      "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
      " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
      "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
      " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
      "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
      " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
      "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
      "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
      "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
      " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
      " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
      "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
      "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
      "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
      "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n"
     ]
    }
   ],
   "source": [
    "#Acess vector for one word\n",
    "print(model_cbow.wv['dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff315a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between eats and bites: -0.013497081\n",
      "Similarity between eats and man: -0.052354366\n"
     ]
    }
   ],
   "source": [
    "#Compute similarity \n",
    "print(\"Similarity between eats and bites:\",model_cbow.wv.similarity('eats', 'bites'))\n",
    "print(\"Similarity between eats and man:\",model_cbow.wv.similarity('eats', 'man'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5058f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('food', 0.13887982070446014),\n",
       " ('bites', 0.13149003684520721),\n",
       " ('eats', 0.06422407925128937),\n",
       " ('dog', 0.009391157887876034),\n",
       " ('man', -0.05987631157040596)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Most similarity\n",
    "model_cbow.wv.most_similar('meat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2ba171",
   "metadata": {},
   "source": [
    "### SkipGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77d8ead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=6, vector_size=100, alpha=0.025>\n",
      "['man', 'dog', 'eats', 'bites', 'food', 'meat']\n",
      "[-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
      "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
      " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
      " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
      "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
      "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
      "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
      " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
      " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
      "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
      "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
      " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
      "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
      " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
      "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
      " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
      "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
      "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
      "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
      " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
      " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
      "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
      "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
      "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
      "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n"
     ]
    }
   ],
   "source": [
    "#Summarize the loaded model\n",
    "print(model_skipgram)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(model_skipgram.wv.key_to_index)\n",
    "print(words)\n",
    "\n",
    "#Acess vector for one word\n",
    "print(model_skipgram.wv['dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be788db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between eats and bites: -0.013518769\n",
      "Similarity between eats and man: -0.052345097\n"
     ]
    }
   ],
   "source": [
    "#Compute similarity \n",
    "print(\"Similarity between eats and bites:\",model_skipgram.wv.similarity('eats', 'bites'))\n",
    "print(\"Similarity between eats and man:\",model_skipgram.wv.similarity('eats', 'man'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478fcdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('food', 0.13887983560562134),\n",
       " ('bites', 0.13149002194404602),\n",
       " ('eats', 0.06406079977750778),\n",
       " ('dog', 0.009391169995069504),\n",
       " ('man', -0.059876300394535065)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Most similarity\n",
    "model_skipgram.wv.most_similar('meat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1b4209",
   "metadata": {},
   "source": [
    "## Training Your Embedding on Wiki Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684dff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./data/enwiki-latest-pages-articles14.xml-p13159683p14324602.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "844b13b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.wikicorpus import WikiCorpus\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64a29d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Choukrallah Lachhab\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1333: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected %s; aliasing chunkize to chunkize_serial\" % entity)\n"
     ]
    }
   ],
   "source": [
    "wiki = WikiCorpus(file_name,dictionary={})\n",
    "sentences = list(wiki.get_texts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9de55106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84243"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70220f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW Model Training Complete.\n",
      "Time taken for training is:0.07 hrs \n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "word2vec_cbow = Word2Vec(sentences,min_count=10, sg=0)\n",
    "end = time.time()\n",
    "\n",
    "print(\"CBOW Model Training Complete.\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81a4bde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=114701, vector_size=100, alpha=0.025>\n",
      "------------------------------\n",
      "Length of vocabulary: 114701\n",
      "Printing the first 30 words.\n",
      "['the', 'of', 'and', 'in', 'to', 'was', 'is', 'for', 'on', 'as', 'by', 'with', 'he', 'at', 'from', 'that', 'his', 'it', 'an', 'also', 'were', 'which', 'are', 'this', 'new', 'first', 'be', 'or', 'had', 'one']\n",
      "------------------------------\n",
      "Length of vector: 100\n",
      "[ 2.4798193   1.6299644  -1.9524587  -2.1632767  -0.8015589  -2.4180744\n",
      " -0.9288921   0.6917903  -0.7427525  -0.9527898   0.33223364 -1.7923205\n",
      "  1.3321561  -0.573788   -0.56123525  0.7331837  -0.7210635  -1.9034867\n",
      " -1.0594628  -3.8944588   0.82641625 -1.0394018  -0.27613482  0.999485\n",
      " -2.9894524   0.7632584  -2.2548194  -2.9809794  -0.796569    1.1142012\n",
      " -0.78130347  0.03968257  0.6680792   0.46015945  1.2809261   1.9576032\n",
      " -2.3656642   1.3889844   1.8410498  -2.6152942   0.4751164   0.5279017\n",
      " -0.09113584 -3.0415146  -1.247852   -0.46009392  2.3148615  -1.9470344\n",
      "  3.566701   -2.9577441  -1.1105081  -1.3227042   0.27546388  2.608925\n",
      " -0.3348018  -0.24360932 -3.8519638  -1.8212883  -0.62497866 -2.3002558\n",
      " -0.9451101  -0.89252394 -0.2383269   4.843974   -0.16423525 -2.8762016\n",
      "  2.4795792  -0.61511606  4.013769   -1.1316683   0.5624143   1.8807926\n",
      "  1.5838242  -1.4642005   0.9129873   4.858961    0.58216375 -0.481933\n",
      " -0.63262504 -1.6774757  -0.02209902 -0.3374616   2.676413   -2.259518\n",
      " -0.91567314  1.8265291   0.03542297 -0.19550137  0.7323034   3.8509893\n",
      "  0.6674965   0.00779776 -2.9912164   2.0857954   0.10995804 -1.3966193\n",
      "  1.297535    0.16442776  4.1289682  -3.5110724 ]\n",
      "------------------------------\n",
      "Similarity between film and drama: 0.5261199\n",
      "Similarity between film and tiger: 0.21010026\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Summarize the loaded model\n",
    "print(word2vec_cbow)\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(word2vec_cbow.wv.key_to_index)\n",
    "print(f\"Length of vocabulary: {len(words)}\")\n",
    "print(\"Printing the first 30 words.\")\n",
    "print(words[:30])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Acess vector for one word\n",
    "print(f\"Length of vector: {len(word2vec_cbow.wv['film'])}\")\n",
    "print(word2vec_cbow.wv['film'])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Compute similarity \n",
    "print(\"Similarity between film and drama:\",word2vec_cbow.wv.similarity('film', 'drama'))\n",
    "print(\"Similarity between film and tiger:\",word2vec_cbow.wv.similarity('film', 'tiger'))\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb3ad554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "from gensim.models import Word2Vec, KeyedVectors   \n",
    "word2vec_cbow.wv.save_word2vec_format('word2vec_cbow.bin', binary=True)\n",
    "\n",
    "# load model\n",
    "# new_modelword2vec_cbow = Word2Vec.load('word2vec_cbow.bin')\n",
    "# print(word2vec_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40b3705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram Model Training Complete\n",
      "Time taken for training is:0.24 hrs \n"
     ]
    }
   ],
   "source": [
    "#SkipGram\n",
    "start = time.time()\n",
    "word2vec_skipgram = Word2Vec(sentences,min_count=10, sg=1)\n",
    "end = time.time()\n",
    "\n",
    "print(\"SkipGram Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "843a4d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=114701, vector_size=100, alpha=0.025>\n",
      "------------------------------\n",
      "Length of vocabulary: 114701\n",
      "Printing the first 30 words.\n",
      "['the', 'of', 'and', 'in', 'to', 'was', 'is', 'for', 'on', 'as', 'by', 'with', 'he', 'at', 'from', 'that', 'his', 'it', 'an', 'also', 'were', 'which', 'are', 'this', 'new', 'first', 'be', 'or', 'had', 'one']\n",
      "------------------------------\n",
      "Length of vector: 100\n",
      "[ 0.25086927  0.34926364  0.32676318  0.34735006 -0.45518517 -0.00476236\n",
      " -0.00720366  0.6344674  -0.35669264 -0.27744132 -0.25112808 -0.42255458\n",
      "  0.08205581  0.19419374 -0.586225    0.23438483  0.50972617  0.04808903\n",
      " -0.00883848 -0.49342445  0.12556285  0.19866785  0.21498752 -0.17337641\n",
      " -0.2987177   0.15012065 -0.50872517  0.3349206  -0.1557765   0.04826428\n",
      " -0.1847301  -0.50891805  0.35367274 -0.21916309 -0.19245264  0.3085634\n",
      " -0.00641272 -0.02233523  0.02466761 -0.59897727 -0.21583591  0.51929414\n",
      " -0.18047728 -0.30008414  0.44648957  0.09496464  0.01635326 -0.39480928\n",
      "  0.19230269 -0.02501836  0.10321771  0.05481143 -0.22634357 -0.04535987\n",
      " -0.15565662  0.1675725  -0.6290048  -0.6581971   0.12099493  0.26588517\n",
      " -0.072461   -0.0527341  -0.6909345   0.8001985  -0.15198344  0.2931631\n",
      "  0.14281721  0.21627112 -0.08925387  0.5222544  -0.03026565 -0.17825209\n",
      " -0.01194412 -0.7467729   0.19107361  0.52089536  0.04832907 -0.31632307\n",
      " -0.5530306  -0.42075962 -0.35422     0.1466378   0.36013842  0.60574985\n",
      " -0.23101397 -0.18509851  0.19739631 -0.07611071  0.30292183  0.51247627\n",
      " -0.6737866   0.31769818  0.26494032  0.2514566   0.14200038 -0.21304098\n",
      " -0.6108881  -0.38034466  0.38897318 -0.46294835]\n",
      "------------------------------\n",
      "Similarity between film and drama: 0.6347717\n",
      "Similarity between film and tiger: 0.25022626\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Summarize the loaded model\n",
    "print(word2vec_skipgram)\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(word2vec_skipgram.wv.key_to_index)\n",
    "print(f\"Length of vocabulary: {len(words)}\")\n",
    "print(\"Printing the first 30 words.\")\n",
    "print(words[:30])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Acess vector for one word\n",
    "print(f\"Length of vector: {len(word2vec_skipgram.wv['film'])}\")\n",
    "print(word2vec_skipgram.wv['film'])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Compute similarity \n",
    "print(\"Similarity between film and drama:\",word2vec_skipgram.wv.similarity('film', 'drama'))\n",
    "print(\"Similarity between film and tiger:\",word2vec_skipgram.wv.similarity('film', 'tiger'))\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f936a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# word2vec_skipgram.wv.save_word2vec_format('word2vec_sg.bin', binary=True)\n",
    "\n",
    "# load model\n",
    "# new_model_skipgram = Word2Vec.load('model_skipgram.bin')\n",
    "# print(model_skipgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe4c42a",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8443d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText CBOW Model Training Complete\n",
      "Time taken for training is:0.36 hrs \n"
     ]
    }
   ],
   "source": [
    "#CBOW\n",
    "start = time.time()\n",
    "fasttext_cbow = FastText(sentences, sg=0, min_count=10)\n",
    "end = time.time()\n",
    "\n",
    "print(\"FastText CBOW Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faa7a881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText<vocab=114701, vector_size=100, alpha=0.025>\n",
      "------------------------------\n",
      "Length of vocabulary: 114701\n",
      "Printing the first 30 words.\n",
      "['the', 'of', 'and', 'in', 'to', 'was', 'is', 'for', 'on', 'as', 'by', 'with', 'he', 'at', 'from', 'that', 'his', 'it', 'an', 'also', 'were', 'which', 'are', 'this', 'new', 'first', 'be', 'or', 'had', 'one']\n",
      "------------------------------\n",
      "Length of vector: 100\n",
      "[-1.1028962  -1.1424731   4.2971435   3.093765   -1.9298153  -1.573785\n",
      "  0.7352989  -0.06200884  4.0854506   2.5948439   6.03334    -1.5191512\n",
      " -2.8226764   2.422655   -0.02007237  4.245388    1.9633343  -1.2209948\n",
      " -0.225725    5.744732    0.15987073  2.4027047  -4.1807213   2.2000227\n",
      " -1.6735848   1.5635186   3.8370767   1.9344715  -2.2298977   2.3143842\n",
      "  0.30345052 -4.899117    0.57759863 -2.098047   -3.9966545   4.096216\n",
      "  6.4856396   1.3798109   2.9979613   0.41648358 -0.56078905 -2.5152786\n",
      "  1.3450183   1.1636597  -4.128712   -4.2033005  -0.20914441  3.489923\n",
      " -1.6094836  -1.2102098   2.4624026  -0.10070146 -3.6332452   3.3410897\n",
      " -4.278539   -1.7885392  -1.8078083   1.9369096  -1.6186334   1.5607872\n",
      "  0.5575447   2.4067714   0.3991621   4.750349    3.3086977   4.926495\n",
      " -4.393475   -0.06706763  2.6876855   0.43840134 -0.77531546  5.4086056\n",
      "  6.690163   -0.6951163  -2.023879    0.5596778   4.4500666   1.1354625\n",
      "  2.6067488   0.73594     4.776858   -1.8501903  -3.0013583   2.028414\n",
      " -1.375085   -4.014046    0.06098046 -1.0508633  -5.273743    1.3959973\n",
      "  2.139818   -1.6385134  -8.930556    1.5452882   1.9191234  -5.4566326\n",
      " -0.19579233  3.0902185  -1.9141074  -1.9495486 ]\n",
      "------------------------------\n",
      "Similarity between film and drama: 0.58315957\n",
      "Similarity between film and tiger: 0.24562852\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Summarize the loaded model\n",
    "print(fasttext_cbow)\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(fasttext_cbow.wv.key_to_index)\n",
    "print(f\"Length of vocabulary: {len(words)}\")\n",
    "print(\"Printing the first 30 words.\")\n",
    "print(words[:30])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Acess vector for one word\n",
    "print(f\"Length of vector: {len(fasttext_cbow.wv['film'])}\")\n",
    "print(fasttext_cbow.wv['film'])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Compute similarity \n",
    "print(\"Similarity between film and drama:\",fasttext_cbow.wv.similarity('film', 'drama'))\n",
    "print(\"Similarity between film and tiger:\",fasttext_cbow.wv.similarity('film', 'tiger'))\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2c06bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText SkipGram Model Training Complete\n",
      "Time taken for training is:0.56 hrs \n"
     ]
    }
   ],
   "source": [
    "#SkipGram\n",
    "start = time.time()\n",
    "fasttext_skipgram = FastText(sentences, sg=1, min_count=10)\n",
    "end = time.time()\n",
    "\n",
    "print(\"FastText SkipGram Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1405e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText<vocab=114701, vector_size=100, alpha=0.025>\n",
      "------------------------------\n",
      "Length of vocabulary: 114701\n",
      "Printing the first 30 words.\n",
      "['the', 'of', 'and', 'in', 'to', 'was', 'is', 'for', 'on', 'as', 'by', 'with', 'he', 'at', 'from', 'that', 'his', 'it', 'an', 'also', 'were', 'which', 'are', 'this', 'new', 'first', 'be', 'or', 'had', 'one']\n",
      "------------------------------\n",
      "Length of vector: 100\n",
      "[-1.1028962  -1.1424731   4.2971435   3.093765   -1.9298153  -1.573785\n",
      "  0.7352989  -0.06200884  4.0854506   2.5948439   6.03334    -1.5191512\n",
      " -2.8226764   2.422655   -0.02007237  4.245388    1.9633343  -1.2209948\n",
      " -0.225725    5.744732    0.15987073  2.4027047  -4.1807213   2.2000227\n",
      " -1.6735848   1.5635186   3.8370767   1.9344715  -2.2298977   2.3143842\n",
      "  0.30345052 -4.899117    0.57759863 -2.098047   -3.9966545   4.096216\n",
      "  6.4856396   1.3798109   2.9979613   0.41648358 -0.56078905 -2.5152786\n",
      "  1.3450183   1.1636597  -4.128712   -4.2033005  -0.20914441  3.489923\n",
      " -1.6094836  -1.2102098   2.4624026  -0.10070146 -3.6332452   3.3410897\n",
      " -4.278539   -1.7885392  -1.8078083   1.9369096  -1.6186334   1.5607872\n",
      "  0.5575447   2.4067714   0.3991621   4.750349    3.3086977   4.926495\n",
      " -4.393475   -0.06706763  2.6876855   0.43840134 -0.77531546  5.4086056\n",
      "  6.690163   -0.6951163  -2.023879    0.5596778   4.4500666   1.1354625\n",
      "  2.6067488   0.73594     4.776858   -1.8501903  -3.0013583   2.028414\n",
      " -1.375085   -4.014046    0.06098046 -1.0508633  -5.273743    1.3959973\n",
      "  2.139818   -1.6385134  -8.930556    1.5452882   1.9191234  -5.4566326\n",
      " -0.19579233  3.0902185  -1.9141074  -1.9495486 ]\n",
      "------------------------------\n",
      "Similarity between film and drama: 0.58315957\n",
      "Similarity between film and tiger: 0.24562852\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Summarize the loaded model\n",
    "print(fasttext_cbow)\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(fasttext_cbow.wv.key_to_index)\n",
    "print(f\"Length of vocabulary: {len(words)}\")\n",
    "print(\"Printing the first 30 words.\")\n",
    "print(words[:30])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Acess vector for one word\n",
    "print(f\"Length of vector: {len(fasttext_cbow.wv['film'])}\")\n",
    "print(fasttext_cbow.wv['film'])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Compute similarity \n",
    "print(\"Similarity between film and drama:\",fasttext_cbow.wv.similarity('film', 'drama'))\n",
    "print(\"Similarity between film and tiger:\",fasttext_cbow.wv.similarity('film', 'tiger'))\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "014daa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText SkipGram Model Training Complete\n",
      "Time taken for training is:0.50 hrs \n"
     ]
    }
   ],
   "source": [
    "#SkipGram\n",
    "start = time.time()\n",
    "fasttext_skipgram = FastText(sentences, sg=1, min_count=10)\n",
    "end = time.time()\n",
    "\n",
    "print(\"FastText SkipGram Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd8f49a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText<vocab=114701, vector_size=100, alpha=0.025>\n",
      "------------------------------\n",
      "Length of vocabulary: 114701\n",
      "Printing the first 30 words.\n",
      "['the', 'of', 'and', 'in', 'to', 'was', 'is', 'for', 'on', 'as', 'by', 'with', 'he', 'at', 'from', 'that', 'his', 'it', 'an', 'also', 'were', 'which', 'are', 'this', 'new', 'first', 'be', 'or', 'had', 'one']\n",
      "------------------------------\n",
      "Length of vector: 100\n",
      "[ 4.36875135e-01  3.03066134e-01  3.18868384e-02 -2.42166236e-01\n",
      " -1.42180741e-01  1.99038222e-01  6.16607890e-02 -2.71127194e-01\n",
      " -4.55392361e-01 -1.19545072e-01 -7.79057965e-02 -2.10862458e-02\n",
      " -7.12426722e-01  4.58694428e-01 -5.59816360e-01 -5.22863805e-01\n",
      " -2.62240857e-01 -5.13919815e-02  2.89212465e-01 -4.99249756e-01\n",
      " -7.91127037e-04  4.60370719e-01  1.74896657e-01  3.30697030e-01\n",
      "  1.16966538e-01  7.87553489e-02  1.82809398e-01 -4.64557379e-01\n",
      " -2.84144521e-01 -3.36322375e-02 -4.36833858e-01  7.42739737e-02\n",
      "  3.63787651e-01 -2.61090606e-01 -4.08437163e-01 -7.42567778e-01\n",
      "  5.75121343e-01  1.58777326e-01 -4.35391784e-01  2.94529170e-01\n",
      "  4.94098626e-02  2.84605473e-01  1.69917390e-01 -3.14405173e-01\n",
      "  1.85571805e-01  2.34439224e-01 -1.11352116e-01  8.01193640e-02\n",
      " -1.09969132e-01 -1.08317852e-01  2.29633704e-01 -1.66994393e-01\n",
      " -3.82422805e-01  6.62401170e-02  1.63703457e-01 -2.37602536e-02\n",
      " -3.35666806e-01 -2.86540333e-02  2.20955908e-01  4.30068880e-01\n",
      " -3.63243401e-01  1.92051589e-01 -1.81039885e-01  3.78716379e-01\n",
      " -7.91231617e-02  3.95032048e-01  3.26763034e-01 -1.16057441e-01\n",
      "  2.12563053e-02  3.56700748e-01 -7.82241151e-02  1.16398609e+00\n",
      "  5.09713411e-01  1.94384038e-01 -2.53504246e-01 -1.01961851e-01\n",
      " -9.26144570e-02 -2.58793861e-01 -2.55618840e-01  4.73702587e-02\n",
      " -1.19375817e-01 -5.98062612e-02 -6.46980032e-02  2.18168512e-01\n",
      " -1.06292456e-01 -8.43393564e-01  5.22333980e-01 -1.32454693e-01\n",
      " -3.77140701e-01  6.55944824e-01  3.06242675e-01 -1.78179089e-02\n",
      "  1.85883179e-01  6.34074748e-01  6.16685748e-02  3.87171388e-01\n",
      "  1.56340137e-01  1.87562957e-01 -3.63409892e-02  4.23825443e-01]\n",
      "------------------------------\n",
      "Similarity between film and drama: 0.6534719\n",
      "Similarity between film and tiger: 0.34277833\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Summarize the loaded model\n",
    "print(fasttext_skipgram)\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(fasttext_skipgram.wv.key_to_index)\n",
    "print(f\"Length of vocabulary: {len(words)}\")\n",
    "print(\"Printing the first 30 words.\")\n",
    "print(words[:30])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Acess vector for one word\n",
    "print(f\"Length of vector: {len(fasttext_skipgram.wv['film'])}\")\n",
    "print(fasttext_skipgram.wv['film'])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Compute similarity \n",
    "print(\"Similarity between film and drama:\",fasttext_skipgram.wv.similarity('film', 'drama'))\n",
    "print(\"Similarity between film and tiger:\",fasttext_skipgram.wv.similarity('film', 'tiger'))\n",
    "print(\"-\"*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
